{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare sample point neighborhood stats within each study region\n",
    "### *use odense as an example in this notebook\n",
    "Description: This script is for preparing all sample points indicators/stats.  \n",
    "All the cities should run this script first to get the pre-prepared sample points before running the aggregation scripts (aggr.py)\n",
    "\n",
    "**City-specific input data**  \n",
    "\n",
    "| Input data | Geometry | Description |\n",
    "| --- | --- | --- |\n",
    "| aos_nodes_30m_line | point | Public open space pseudo entry points (points on boundary of park every 20m within 30m of road) |\n",
    "| clean_intersections_12m |\tpoint |\tClean intersections (not required; counts are associated with pop_ghs_2015) |\n",
    "| dest_type\t| NA (non-spatial) |\tSummary of destinations and counts |\n",
    "| destinations |\tpoint\t| OSM destinations retrieved using specified definitions (only require: supermarkets, convenience,  pt_any --- use dest_name_full to determine, will need to combine convenience destinations) |\n",
    "| pop_ghs_2015\t| polygon\t| 250m hex grid, associated with area_sqkm (fixed), population estimate (2015), population per sq km, intersection count, intersections per sq km |\n",
    "| urban_sample_points |\tpoint |\tSample points in urban region (every 30m along pedestrian network) |\n",
    "| urban_study_region | polygon | Urban study region (intersection of city boundary and GHS 2015 urban centre layer) |\n",
    "\n",
    "\n",
    "**Two outputs:**\n",
    "1. average poplulation and intersection density per sample point\n",
    "2. accessibility, daily living and walkability score per sample point\n",
    "\n",
    "notice: must close the geopackage connection in QGIS.Otherwise, an error occurred when reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import osmnx as ox\n",
    "import numpy as np\n",
    "import os\n",
    "import setup_sp as ssp # functions for setting up sample point stats used in this notebook\n",
    "import setup_config as sc # import project config parameters\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count, Value, Manager, Process\n",
    "from functools import partial\n",
    "import json\n",
    "import fiona\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the processing city name to users\n",
    "today = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# get the work directory\n",
    "dirname = os.path.abspath(\"\")\n",
    "\n",
    "city = sys.argv[1]\n",
    "configuration_file = f'configuration/vic.py'\n",
    "\n",
    "assumptions = \"\"\"\n",
    "This code assumes the name of a known city to be passed as an argument, however none was provided.\n",
    "\n",
    "Configuration python files containing the dictionaries 'config' and 'parameters' are written\n",
    "to the ./configuration directory for cities through use of the set up configuration script setup_config.py,\n",
    "like so: \n",
    "python setup_config.py auckland\n",
    "\n",
    "or, to generate set up scripts for all cities\n",
    "python setup_config.py\n",
    "\"\"\"\n",
    "    \n",
    "try:\n",
    "    exec(open(configuration_file).read())\n",
    "except Exception as e:\n",
    "    print(f\"Failed to read configuration file {configuration_file}.\\n\\n{assumptions}\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global indicators project 2021-02-23\n",
      "\n",
      "Process city: Vic\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nGlobal indicators project {today}\\n\\nProcess city: {config['study_region'].title()}\\n\")\n",
    "\n",
    "# geopackage path where to read all the required layers\n",
    "gpkgPath = os.path.join(dirname, config[\"folder\"], config[\"geopackagePath\"])   \n",
    "\n",
    "# define original graphml filepath\n",
    "ori_graphml_filepath = os.path.join(dirname, config[\"folder\"], config[\"graphmlName\"])\n",
    "\n",
    "if not os.path.exists(gpkgPath):\n",
    "    # check if these files are located in the study region folder (ie. output location for pre-processing)\n",
    "    alt_dir = f\"./data/study_region/{config['study_region_full']}\"\n",
    "    alt_sources = (f\"{alt_dir}/{os.path.basename(gpkgPath)}\",\n",
    "                   f\"{alt_dir}/{os.path.basename(ori_graphml_filepath)}\")\n",
    "    if sum([os.path.exists(x) for x in alt_sources])==2:\n",
    "        gpkgPath,ori_graphml_filepath = alt_sources\n",
    "    else:\n",
    "        sys.exit(f\"\\nThe required input files ({os.path.basename(gpkgPath)} and {os.path.basename(gpkgPath)}) \"\n",
    "         f\"do not appear to exist in either the ./data/input folder or {alt_dir} folder.  \"\n",
    "         \"Please ensure both of these file exist in one of these locations, or that the input \"\n",
    "         \"configuration is correctly re-parameterised to recognise an alternative location.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read network from disk.\n",
      "  - Ensure graph is undirected.\n"
     ]
    }
   ],
   "source": [
    "# geopackage path where to save processing layers\n",
    "gpkgPath_output = os.path.join(dirname, config[\"folder\"], config[\"geopackagePath_output\"])\n",
    "\n",
    "# Check if geopackage has a -wal file associated with it\n",
    "# if so it is likely open and locked for use by another software package (e.g. QGIS)\n",
    "# and will be unable to be used\n",
    "for required_gpkg in [gpkgPath,gpkgPath_output]:\n",
    "    if os.path.exists(f'{required_gpkg}-wal'):\n",
    "        sys.exit(\n",
    "        f\"\\nIt appears that the required geopackage {required_gpkg} may be open in another software package, \" \n",
    "        \"due to the presence of a Write Ahead Logging (WAL) file associated with it.  Please ensure that the input \"  \n",
    "        \"geopackage is not being used in any other software before continuing, and that the file \"\n",
    "       f\"'{required_gpkg}-wal' is not present before continuing.\"\n",
    "       )\n",
    "\n",
    "# read projected graphml filepath\n",
    "proj_graphml_filepath = os.path.join(dirname, config[\"folder\"], config[\"graphmlProj_name\"])\n",
    "\n",
    "G_proj = ssp.read_proj_graphml(proj_graphml_filepath,\n",
    "                               ori_graphml_filepath, \n",
    "                               config[\"to_crs\"],\n",
    "                               undirected=True,\n",
    "                               retain_fields=['osmid','length'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample point geopackage exists.\n"
     ]
    }
   ],
   "source": [
    "# copy input geopackage to output geopackage, if not already exist\n",
    "input_layers = fiona.listlayers(gpkgPath)\n",
    "if not os.path.isfile(gpkgPath_output):\n",
    "    print(\"Initialise sample point output geopackage as a copy of input geopackage\")\n",
    "    os.system(f'cp {gpkgPath} {gpkgPath_output}')\n",
    "    output_layers = input_layers\n",
    "else:\n",
    "    output_layers = fiona.listlayers(gpkgPath_output)\n",
    "    print(\"Sample point geopackage exists.\")\n",
    "    for layer in [x for x in input_layers if x not in output_layers]:\n",
    "        print(f\" - updating output geopackage to contain the layer '{layer}'\")\n",
    "        gpkgPath_input = gpd.read_file(gpkgPath, layer=layer)\n",
    "        gpkgPath_input.to_file(gpkgPath_output, layer=layer, driver=\"GPKG\")\n",
    "\n",
    "# read hexagon layer of the city from disk, the hexagon layer is 250m*250m\n",
    "# it should contain population estimates and intersection information\n",
    "hexes = gpd.read_file(gpkgPath_output, layer=parameters[\"hex250\"])\n",
    "hexes.set_index('index',inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calculate average poplulation and intersection density for each sample point in study regions\n",
    "**The steps are as follows:**\n",
    "1. use the OSM pedestrain network (graphml in disk) to generate local 1600m neighborhood per urban sample points (sample point in disk)\n",
    "2. load 250m hex grid from disk with population and network intersections density data\n",
    "3. then calculate population and intersection density within each local walkable neighborhood (1600m) by averaging the hex level pop and intersection density data; final result is urban sample point dataframe with osmid, pop density, and intersection density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First pass node-level neighbourhood analysis (Calculate average population and intersection density for each intersection node in study regions, taking mean values from distinct hexes within neighbourhood buffer distance)\n",
      "  - Read population and intersection density from local file.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFirst pass node-level neighbourhood analysis (Calculate average population and intersection density \"\n",
    "      \"for each intersection node in study regions, taking mean values from distinct hexes within \"\n",
    "      \"neighbourhood buffer distance)\")\n",
    "nh_startTime = time.time()\n",
    "population_density = parameters[\"population_density\"]\n",
    "intersection_density = parameters[\"intersection_density\"]\n",
    "nh_fields_points = [population_density,intersection_density]\n",
    "# read from disk if exist\n",
    "if 'nodes_pop_intersect_density' in output_layers:                        \n",
    "    print(\"  - Read population and intersection density from local file.\")\n",
    "    gdf_nodes_simple = gpd.read_file(gpkgPath_output, layer='nodes_pop_intersect_density')\n",
    "    gdf_nodes_simple.set_index('osmid', inplace=True)\n",
    "else:\n",
    "    print(\"  - Set up simple nodes\")\n",
    "    gdf_nodes = ox.graph_to_gdfs(G_proj, nodes=True, edges=False)\n",
    "    gdf_nodes.osmid = gdf_nodes.osmid.astype(int)\n",
    "    gdf_nodes = gdf_nodes.drop_duplicates(subset=\"osmid\")\n",
    "    gdf_nodes.set_index('osmid', inplace=True)\n",
    "    # associate nodes with hex_id\n",
    "    gdf_nodes = ssp.spatial_join_index_to_gdf(gdf_nodes, hexes, right_index_name='hex_id',join_type='within')\n",
    "    # keep only the unique node id column\n",
    "    gdf_nodes = gdf_nodes[[\"hex_id\",\"geometry\"]]\n",
    "    # drop any nodes which are na (they are outside the buffered study region and not of interest)\n",
    "    gdf_nodes_simple = gdf_nodes[~gdf_nodes.hex_id.isna()].copy()\n",
    "    gdf_nodes = gdf_nodes[[\"hex_id\"]]\n",
    "\n",
    "if len([x for x in nh_fields_points if x not in gdf_nodes_simple.columns]) > 0:\n",
    "    # Calculate average population and intersection density for each intersection node in study regions\n",
    "    # taking mean values from distinct hexes within neighbourhood buffer distance\n",
    "    nh_fields_hex = ['pop_per_sqkm','intersections_per_sqkm']   \n",
    "    # Create a dictionary of edge index and integer values of length\n",
    "    # The length attribute was saved as string, so must be recast to use as weight\n",
    "    # The units are meters, so the decimal precision is unnecessary (error is larger than this; meter is adequate)\n",
    "    weight = dict(zip([k for k in G_proj.edges],[int(float(G_proj.edges[k]['length'])) for k in G_proj.edges]))\n",
    "\n",
    "    # Add a new edge attribute using the integer weights\n",
    "    nx.set_edge_attributes(G_proj, weight, 'weight')\n",
    "\n",
    "    # run all pairs analysis\n",
    "    total_nodes = len(gdf_nodes_simple)\n",
    "    nh_distance = parameters[\"neighbourhood_distance\"]\n",
    "    print(f'  - Generate {nh_distance}m  neighbourhoods for nodes (All pairs Dijkstra shortest path analysis)')\n",
    "    all_pairs_d = pd.DataFrame([(k,v.keys()) for k,v in tqdm(nx.all_pairs_dijkstra_path_length(G_proj,1000,'weight'),\n",
    "                                        total=total_nodes,unit='nodes',desc=' '*18)],\n",
    "                  columns = ['osmid','nodes']).set_index('osmid')\n",
    "    # extract results\n",
    "    print('  - Summarise attributes (average value from unique associated hexes within nh buffer distance)...')\n",
    "\n",
    "    result = pd.DataFrame([tuple(hexes.loc[gdf_nodes.loc[all_pairs_d.loc[n].nodes,'hex_id'].dropna().unique(),    \n",
    "                                    nh_fields_hex].mean().values) for index,n in    \n",
    "                                        tqdm(np.ndenumerate(gdf_nodes_simple.index.values),total=total_nodes,desc=' '*18)],\n",
    "                     columns = nh_fields_points,\n",
    "                     index=gdf_nodes_simple.index.values)\n",
    "    gdf_nodes_simple = gdf_nodes_simple.join(result)\n",
    "\n",
    "    # save in geopackage (so output files are all kept together)\n",
    "    gdf_nodes_simple.to_file(gpkgPath_output, layer='nodes_pop_intersect_density', driver=\"GPKG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_id</th>\n",
       "      <th>sp_local_nh_avg_pop_density</th>\n",
       "      <th>sp_local_nh_avg_intersection_density</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>osmid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>525877251</th>\n",
       "      <td>1651</td>\n",
       "      <td>5686.545508</td>\n",
       "      <td>129.574042</td>\n",
       "      <td>POINT (437779.504 4642789.855)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838986757</th>\n",
       "      <td>237</td>\n",
       "      <td>28.767408</td>\n",
       "      <td>45.213903</td>\n",
       "      <td>POINT (436536.381 4637542.143)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625751561</th>\n",
       "      <td>1784</td>\n",
       "      <td>1746.464938</td>\n",
       "      <td>89.680468</td>\n",
       "      <td>POINT (436586.031 4643103.392)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521781258</th>\n",
       "      <td>1055</td>\n",
       "      <td>1111.435046</td>\n",
       "      <td>39.459406</td>\n",
       "      <td>POINT (441362.048 4640785.311)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377116692</th>\n",
       "      <td>2492</td>\n",
       "      <td>27.835967</td>\n",
       "      <td>32.060767</td>\n",
       "      <td>POINT (439640.738 4647011.830)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hex_id  sp_local_nh_avg_pop_density  \\\n",
       "osmid                                             \n",
       "525877251     1651                  5686.545508   \n",
       "2838986757     237                    28.767408   \n",
       "1625751561    1784                  1746.464938   \n",
       "521781258     1055                  1111.435046   \n",
       "4377116692    2492                    27.835967   \n",
       "\n",
       "            sp_local_nh_avg_intersection_density  \\\n",
       "osmid                                              \n",
       "525877251                             129.574042   \n",
       "2838986757                             45.213903   \n",
       "1625751561                             89.680468   \n",
       "521781258                              39.459406   \n",
       "4377116692                             32.060767   \n",
       "\n",
       "                                  geometry  \n",
       "osmid                                       \n",
       "525877251   POINT (437779.504 4642789.855)  \n",
       "2838986757  POINT (436536.381 4637542.143)  \n",
       "1625751561  POINT (436586.031 4643103.392)  \n",
       "521781258   POINT (441362.048 4640785.311)  \n",
       "4377116692  POINT (439640.738 4647011.830)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show sample point pop and intersection density data\n",
    "gdf_nodes_simple.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate accessibility to POI (supermarket,convenience,pt,pos), daily living and walkability for sample points\n",
    "**steps as follow:**\n",
    "   1. using pandana packadge to calculate distance to access from sample points to destinations (daily living destinations, public open space)\n",
    "   2. calculate accessibiity score per sample point: transform accessibility distance to binary measure: 1 if access <= 500m, 0 otherwise\n",
    "   3. calculate daily living score by summing the accessibiity scores to all POIs (excluding pos)\n",
    "   4. calculate walkability score per sample point: get zscores for daily living accessibility, populaiton density and intersections pop_density; sum these three zscores at sample point level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to calculate or load city local neighbourhood statistics: 0.00890416 mins\n",
      "\n",
      "Calculate assessbility to POIs.\n",
      "\n",
      "Calculating nearest node analyses ...\n",
      "\n",
      "\t- Open street map destinations\n",
      "\t\t['fresh_food_market', 'convenience', 'pt_osm_any']\n",
      "\n",
      "\t- Public open space\n",
      "\t\t['public_open_space_any']\n",
      "\t\t['public_open_space_large']\n",
      "\n",
      "\t- Public transport (GTFS)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time taken to calculate or load city local neighbourhood statistics: {(time.time() - nh_startTime)/60:02g} mins\")\n",
    "\n",
    "# Calculate accessibility to POI (fresh_food_market,convenience,pt,pso) and\n",
    "# walkability for sample points steps as follow:\n",
    "# 1. using pandana packadge to calculate distance to access from sample\n",
    "#    points to destinations (daily living destinations, public open space)\n",
    "# 2. calculate accessibiity score per sample point: transform accessibility\n",
    "#    distance to binary measure: 1 if access <= 500m, 0 otherwise\n",
    "# 3. calculate daily living score by summing the accessibiity scores to all\n",
    "#    POIs (excluding pos)\n",
    "# 4. calculate walkability score per sample point: get zscores for daily\n",
    "#    living accessibility, populaiton density and intersections population_density;\n",
    "#    sum these three zscores at sample point level\n",
    "\n",
    "print(\"\\nCalculate assessbility to POIs.\")\n",
    "# read accessibility distance from configuration file, which is 500m\n",
    "\n",
    "# create the pandana network, use network nodes and edges\n",
    "gdf_nodes, gdf_edges = ox.graph_to_gdfs(G_proj)\n",
    "network = ssp.create_pdna_net(gdf_nodes, gdf_edges, predistance=parameters[\"accessibility_distance\"])\n",
    "\n",
    "distance_results = {}\n",
    "print(\"\\nCalculating nearest node analyses ...\")\n",
    "for analysis_key in config['nearest_node_analyses']:\n",
    "    print(f'\\n\\t- {analysis_key}')\n",
    "    analysis = config['nearest_node_analyses'][analysis_key]\n",
    "    layer_analysis_count = len(analysis['layers'])\n",
    "    for layer in analysis['layers']:\n",
    "        if layer is not None:\n",
    "            output_names = analysis['output_names'].copy()\n",
    "            if layer_analysis_count > 1 and layer_analysis_count==len(analysis['output_names']):\n",
    "                # assume that output names correspond to layers, and refresh per analysis\n",
    "                output_names = [output_names[analysis['layers'].index(layer)]]\n",
    "\n",
    "            print(f'\\t\\t{output_names}')\n",
    "            gdf_poi = gpd.read_file(f\"data/{analysis['geopackage']}\", layer = layer) \n",
    "            distance_results[f'{analysis}_{layer}'] = ssp.cal_dist_node_to_nearest_pois(gdf_poi, \n",
    "                                                         parameters[\"accessibility_distance\"], \n",
    "                                                         network, \n",
    "                                                         category_field = analysis['category_field'],\n",
    "                                                         categories = analysis['categories'],\n",
    "                                                         filter_field = analysis['filter_field'],\n",
    "                                                         filter_iterations = analysis['filter_iterations'],\n",
    "                                                         output_names = output_names,\n",
    "                                                         output_prefix = 'sp_nearest_node_')\n",
    "        else:\n",
    "            # create null results --- e.g. for GTFS analyses where no layer exists\n",
    "            distance_results[f'{analysis_key}_{layer}'] = pd.DataFrame(index=gdf_nodes.index, \n",
    "                                    columns=[f'sp_nearest_node_{x}' for x in analysis['output_names']])\n",
    "\n",
    "# concatenate analysis dataframes into one\n",
    "gdf_nodes_poi_dist = pd.concat([gdf_nodes]+[distance_results[x] for x in distance_results], axis=1)\n",
    "\n",
    "# set index of gdf_nodes_poi_dist, using 'osmid' as the index, and remove other unnecessary columns\n",
    "gdf_nodes_poi_dist.set_index(\"osmid\",inplace=True)\n",
    "unnecessary_columns = [x for x in \n",
    "                         [\"geometry\", \"id\", \"lat\", \"lon\", \"y\", \"x\", \"highway\", \"ref\"] \n",
    "                            if x in gdf_nodes_poi_dist.columns]\n",
    "gdf_nodes_poi_dist.drop(unnecessary_columns,axis=1, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# replace -999 values (meaning no destination reached in less than 500 metres) as nan\n",
    "gdf_nodes_poi_dist = round(gdf_nodes_poi_dist, 0).replace(-999, np.nan).astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read sample points from disk (in city-specific geopackage)\n",
    "samplePointsData = gpd.read_file(gpkgPath_output, layer=parameters[\"samplePoints\"])\n",
    "\n",
    "# create 'hex_id' for sample point, if it not exists\n",
    "if \"hex_id\" not in samplePointsData.columns:\n",
    "    samplePointsData = ssp.spatial_join_index_to_gdf(samplePointsData, hexes, right_index_name='hex_id',join_type='within')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restrict sample points to those not located in hexagons with a population below the minimum threshold value (5)...\n",
      "  491 sample points discarded, leaving 11499 remaining.\n"
     ]
    }
   ],
   "source": [
    "print(\"Restrict sample points to those not located in hexagons with a population below \"\n",
    "      f\"the minimum threshold value ({parameters['pop_min_threshold']})...\"),\n",
    "below_minimum_pop_hex_ids = list(hexes.query(f'pop_est < {parameters[\"pop_min_threshold\"]}').index.values)\n",
    "sample_point_length_pre_discard = len(samplePointsData)\n",
    "samplePointsData = samplePointsData[~samplePointsData.hex_id.isin(below_minimum_pop_hex_ids)]\n",
    "sample_point_length_post_discard = len(samplePointsData)\n",
    "print(f\"  {sample_point_length_pre_discard - sample_point_length_post_discard} sample points discarded, \"\n",
    "      f\"leaving {sample_point_length_post_discard} remaining.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restrict sample points to those with two associated sample nodes...\n",
      "  0 sample points discarded, leaving 11499 remaining.\n",
      "Derive sample point estimates for accessibility and densities based on node distance relations\n",
      "\t - match sample points whose locations coincide with intersections directly with intersection record data\n",
      "\t - for sample points not co-located with intersections, derive estimates by:\n",
      "\t\t - accounting for distances\n",
      "\t\t - calculating proximity-weighted average of density statistics for each sample point\n"
     ]
    }
   ],
   "source": [
    "print(\"Restrict sample points to those with two associated sample nodes...\"),\n",
    "sample_point_length_pre_discard = len(samplePointsData)\n",
    "samplePointsData = samplePointsData.query(f\"n1 in {list(gdf_nodes_simple.index.values)} \"\n",
    "                                          f\"and n2 in {list(gdf_nodes_simple.index.values)}\")\n",
    "sample_point_length_post_discard = len(samplePointsData)\n",
    "print(f\"  {sample_point_length_pre_discard - sample_point_length_post_discard} sample points discarded, \"\n",
    "      f\"leaving {sample_point_length_post_discard} remaining.\")\n",
    "\n",
    "samplePointsData.set_index(\"point_id\", inplace=True)\n",
    "\n",
    "distance_names = list(gdf_nodes_poi_dist.columns)\n",
    "\n",
    "# Estimate full distance to destinations for sample points\n",
    "full_nodes = ssp.create_full_nodes(\n",
    "    samplePointsData,\n",
    "    gdf_nodes_simple,\n",
    "    gdf_nodes_poi_dist,\n",
    "    distance_names,\n",
    "    population_density,\n",
    "    intersection_density,\n",
    ")\n",
    "\n",
    "samplePointsData = samplePointsData[[\"hex_id\", \"edge_ogc_fid\", \"geometry\"]].join(full_nodes, how=\"left\")\n",
    "\n",
    "# create binary distances evaluated against accessibility distance\n",
    "#binary_names = [f\"{x.replace('nearest_node','access')}_binary\" for x in distance_names]\n",
    "#samplePointsData[binary_names] = (samplePointsData[distance_names] <= parameters['accessibility_distance']) \\\n",
    " #                                      .astype(\"Int64\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cumulative opportunities (binary)\n",
    "#1 if d <= access_dist\n",
    "#0 if d > access_dist\n",
    "def binary_access_score(df, distance_names, threshold=500):\n",
    "    \"\"\"\n",
    "    Calculate accessibiity score using binary measure: 1 if access <= access_dist, 0 otherwise\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        DataFrame with origin-destination distances\n",
    "    distance_names: list\n",
    "        list of original distance field names\n",
    "    threshold: int\n",
    "        access distance threshold, default is 500 meters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    df1 = (df[distance_names] <= threshold).fillna(0).astype(int)\n",
    "    return df1\n",
    "\n",
    "\n",
    "#Soft threshold access score\n",
    "#Higgs, C., Badland, H., Simons, K. et al. (2019) The Urban Liveability Index\n",
    "def soft_access_score(df, distance_names, threshold=500, k=5):\n",
    "    \"\"\"\n",
    "    Calculate accessibiity score using soft threshold approach:\n",
    "    1 / (1+ e ^(k *((dist-access_dist)/access_dist)))\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        DataFrame with origin-destination distances\n",
    "    distance_names: list\n",
    "        list of original distance field names\n",
    "    threshold: int\n",
    "        access distance threshold, default is 500 meters\n",
    "    k: int\n",
    "        the slope of decay, default is 5\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    df1 = (1 / (1+numpy.exp(k * ((df[distance_names]-threshold) / threshold)))).fillna(0).astype(float)\n",
    "    return df1\n",
    "\n",
    "#Cumulative-Gaussian\n",
    "#Reference: Vale, D. S., & Pereira, M. (2017).\n",
    "#The influence of the impedance function on gravity-based pedestrian accessibility measures\n",
    "def Cumulative_Gaussian_access_score(df, distance_names, threshold=500, k=129842):\n",
    "    \"\"\"\n",
    "    Calculate accessibiity score using Cumulative-Gaussian approach:\n",
    "    1 if d <= access_dist ; otherwise, e ^(-1 *((d^2)/k)) if d > access_dist\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        DataFrame with origin-destination distances\n",
    "    distance_names: list\n",
    "        list of field names for distance records\n",
    "    threshold: int\n",
    "        access distance threshold\n",
    "    k: int\n",
    "        the slope of decay\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    df1 = df[distance_names].copy()\n",
    "    df1 = df1.astype(float)\n",
    "    df1[df1<=threshold] = 1\n",
    "    df1[df1>threshold] = numpy.exp(-1 * (((df1[df1>threshold]-threshold)**2) / k))\n",
    "    df1 = df1.fillna(0).astype(float)\n",
    "    return(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp_access_fresh_food_market_score</th>\n",
       "      <th>sp_access_convenience_score</th>\n",
       "      <th>sp_access_pt_osm_any_score</th>\n",
       "      <th>sp_access_public_open_space_any_score</th>\n",
       "      <th>sp_access_public_open_space_large_score</th>\n",
       "      <th>sp_access_pt_gtfs_any_score</th>\n",
       "      <th>sp_access_pt_gtfs_freq_30_score</th>\n",
       "      <th>sp_access_pt_gtfs_freq_20_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26336</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26337</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26338</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26339</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26340</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999507</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11499 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sp_access_fresh_food_market_score  sp_access_convenience_score  \\\n",
       "point_id                                                                   \n",
       "1                                       1.0                     1.000000   \n",
       "2                                       1.0                     0.000000   \n",
       "7                                       1.0                     1.000000   \n",
       "8                                       1.0                     1.000000   \n",
       "9                                       1.0                     1.000000   \n",
       "...                                     ...                          ...   \n",
       "26336                                   1.0                     1.000000   \n",
       "26337                                   1.0                     1.000000   \n",
       "26338                                   1.0                     1.000000   \n",
       "26339                                   1.0                     0.000000   \n",
       "26340                                   1.0                     0.999507   \n",
       "\n",
       "          sp_access_pt_osm_any_score  sp_access_public_open_space_any_score  \\\n",
       "point_id                                                                      \n",
       "1                                1.0                                    1.0   \n",
       "2                                1.0                                    1.0   \n",
       "7                                1.0                                    1.0   \n",
       "8                                1.0                                    1.0   \n",
       "9                                1.0                                    1.0   \n",
       "...                              ...                                    ...   \n",
       "26336                            1.0                                    1.0   \n",
       "26337                            1.0                                    1.0   \n",
       "26338                            1.0                                    1.0   \n",
       "26339                            1.0                                    1.0   \n",
       "26340                            1.0                                    1.0   \n",
       "\n",
       "          sp_access_public_open_space_large_score  \\\n",
       "point_id                                            \n",
       "1                                             1.0   \n",
       "2                                             1.0   \n",
       "7                                             1.0   \n",
       "8                                             0.0   \n",
       "9                                             0.0   \n",
       "...                                           ...   \n",
       "26336                                         1.0   \n",
       "26337                                         1.0   \n",
       "26338                                         1.0   \n",
       "26339                                         1.0   \n",
       "26340                                         1.0   \n",
       "\n",
       "          sp_access_pt_gtfs_any_score  sp_access_pt_gtfs_freq_30_score  \\\n",
       "point_id                                                                 \n",
       "1                                 0.0                              0.0   \n",
       "2                                 0.0                              0.0   \n",
       "7                                 0.0                              0.0   \n",
       "8                                 0.0                              0.0   \n",
       "9                                 0.0                              0.0   \n",
       "...                               ...                              ...   \n",
       "26336                             0.0                              0.0   \n",
       "26337                             0.0                              0.0   \n",
       "26338                             0.0                              0.0   \n",
       "26339                             0.0                              0.0   \n",
       "26340                             0.0                              0.0   \n",
       "\n",
       "          sp_access_pt_gtfs_freq_20_score  \n",
       "point_id                                   \n",
       "1                                     0.0  \n",
       "2                                     0.0  \n",
       "7                                     0.0  \n",
       "8                                     0.0  \n",
       "9                                     0.0  \n",
       "...                                   ...  \n",
       "26336                                 0.0  \n",
       "26337                                 0.0  \n",
       "26338                                 0.0  \n",
       "26339                                 0.0  \n",
       "26340                                 0.0  \n",
       "\n",
       "[11499 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#binary\n",
    "binary_names = [f\"{x.replace('nearest_node','access')}_binary\" for x in distance_names]\n",
    "samplePointsData[binary_names] = binary_access_score(samplePointsData, distance_names, parameters['accessibility_distance'])\n",
    "samplePointsData[binary_names]\n",
    "\n",
    "#soft\n",
    "soft_names = [f\"{x.replace('nearest_node','access')}_soft\" for x in distance_names]\n",
    "samplePointsData[soft_names] = soft_access_score(samplePointsData, distance_names, parameters['accessibility_distance'])\n",
    "samplePointsData[soft_names]\n",
    "\n",
    "#c-m\n",
    "c_m_names = [f\"{x.replace('nearest_node','access')}_score\" for x in distance_names]\n",
    "samplePointsData[c_m_names] = Cumulative_Gaussian_access_score(samplePointsData, distance_names, parameters['accessibility_distance'])\n",
    "samplePointsData[c_m_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating sample point specific analyses ...\n",
      "\t - Best PT (any) access score\n",
      "\t - Daily living score\n",
      "\t - Walkability index\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating sample point specific analyses ...\")\n",
    "# Defined in generated config file, e.g. daily living score, walkability index, etc\n",
    "for analysis in config['sample_point_analyses']:\n",
    "    print(f\"\\t - {analysis}\")\n",
    "    for var in config['sample_point_analyses'][analysis]:\n",
    "        columns = config['sample_point_analyses'][analysis][var]['columns']\n",
    "        formula = config['sample_point_analyses'][analysis][var]['formula']\n",
    "        axis    = config['sample_point_analyses'][analysis][var]['axis']\n",
    "        if formula == \"sum\":\n",
    "            samplePointsData[var] = samplePointsData[columns].sum(axis=axis)\n",
    "        if formula == \"max\":\n",
    "            samplePointsData[var] = samplePointsData[columns].max(axis=axis)\n",
    "        if formula == \"sum_of_z_scores\":\n",
    "            samplePointsData[var] =  ((samplePointsData[columns] -  samplePointsData[columns].mean()) \\\n",
    "                                             / samplePointsData[columns].std()).sum(axis=1)       \n",
    "\n",
    "# hex_id and edge_ogc_fid are integers\n",
    "samplePointsData[samplePointsData.columns[0:2]] = samplePointsData[samplePointsData.columns[0:2]].astype(int)\n",
    "# remaining non-geometry fields are float\n",
    "samplePointsData[samplePointsData.columns[3:]] = samplePointsData[samplePointsData.columns[3:]].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11499"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samplePointsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hex_id', 'edge_ogc_fid', 'geometry',\n",
       "       'sp_nearest_node_fresh_food_market', 'sp_nearest_node_convenience',\n",
       "       'sp_nearest_node_pt_osm_any', 'sp_nearest_node_public_open_space_any',\n",
       "       'sp_nearest_node_public_open_space_large',\n",
       "       'sp_nearest_node_pt_gtfs_any', 'sp_nearest_node_pt_gtfs_freq_30',\n",
       "       'sp_nearest_node_pt_gtfs_freq_20', 'sp_local_nh_avg_pop_density',\n",
       "       'sp_local_nh_avg_intersection_density',\n",
       "       'sp_access_fresh_food_market_binary', 'sp_access_convenience_binary',\n",
       "       'sp_access_pt_osm_any_binary', 'sp_access_public_open_space_any_binary',\n",
       "       'sp_access_public_open_space_large_binary',\n",
       "       'sp_access_pt_gtfs_any_binary', 'sp_access_pt_gtfs_freq_30_binary',\n",
       "       'sp_access_pt_gtfs_freq_20_binary', 'sp_access_pt_any_binary',\n",
       "       'sp_daily_living_score', 'sp_walkability_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplePointsData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "point_id\n",
       "1        2.866221\n",
       "2        1.548086\n",
       "7        2.419968\n",
       "8        2.632533\n",
       "9        2.562366\n",
       "           ...   \n",
       "26336    2.295686\n",
       "26337    2.497561\n",
       "26338    2.376695\n",
       "26339    1.620893\n",
       "26340    2.181547\n",
       "Name: sp_daily_living_score, Length: 11499, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samplePointsData['sp_daily_living_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col='sp_walkability_index'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "#plot indicators\n",
    "ax = samplePointsData.plot(ax=ax, column=col, scheme='NaturalBreaks', k=6, cmap='inferno_r', edgecolor='none')\n",
    "\n",
    "ax.set_title(config['study_region'], fontsize=9)\n",
    "ax.set_axis_off()\n",
    "\n",
    "# add a title to the figure\n",
    "fig.suptitle('Local Sample Point walkability', y=0.95, fontsize=10, weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
