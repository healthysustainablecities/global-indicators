"""
Generate global urban heat vulnerability index (GUHVI) through use of the Google Earth Engine API
"""
import sys
import time

# Import Earth Engine and Google Earth Engine Map libraries
import ee
import geemap
import psycopg2
import geopandas as gpd

# import getpass
from script_running_log import script_running_log
from sqlalchemy import text

import ghsci


def fetch_guhvi_data_as_gdf(r: ghsci.Region) -> tuple:
    """Fetch urban study region and AOS public OSM data as GeoDataFrames."""
    # Fetch urban study region data
    with r.engine.connect() as connection:
        urban_study_region_gdf = gpd.read_postgis(
            """
            SELECT ST_Transform(geom, 4326) AS geom
            FROM urban_study_region;
            """,
            connection,
            geom_col='geom',
        )
        
    return urban_study_region_gdf

def compute_guhvi(codename, r):
    """Setup 1km grid and attribute ocean overlap percentage to each cell"""
    # Fetch data for the region
    urban_study_region_gdf = fetch_guhvi_data_as_gdf(r)
    
    # Initialize Google Earth Engine
    project_id = r.config['gee_project_id']
    ee.Initialize(project=project_id)
    
    # Convert GeoDataFrames to Earth Engine FeatureCollections
    urban_study_region_fc = geemap.gdf_to_ee(urban_study_region_gdf, geodesic=False)
    
    # Get the bounding box of the study region
    geometry = urban_study_region_fc.geometry()
    bounding_box = urban_study_region_fc.geometry().bounds()
    
    # Define target year from config file
    target_year = r.config['year']

    # Define the spatial resolution at 1km
    guhvi_scale = 1000
    
    # Define function
    def make_grid(geometry, scale):
        # pixelLonLat returns an image with each pixel labeled with longitude and latitude values.
        lonLat = ee.Image.pixelLonLat()

        # Select the longitude and latitude bands, multiply by a large number then truncate them to integers.
        lonGrid = lonLat.select('longitude').multiply(10000000).toInt()
        latGrid = lonLat.select('latitude').multiply(10000000).toInt()

        # Multiply the latitude and longitude images and then use reduce to vectors.
        grid = lonGrid.multiply(latGrid).reduceToVectors(
            geometry=geometry,
            scale=scale,
            geometryType='polygon'
        )
        
        return grid

    # Define function
    def build_geometry_list(grid, limit):
        geometries = grid.toList(limit)
        geometry_list = []
        for i in range(geometries.size().getInfo()):
            feature = ee.Feature(geometries.get(i))
            feature_geometry = feature.geometry()
            coordinates = feature_geometry.coordinates().get(0)
            geometry_list.append(ee.Geometry.LinearRing(coordinates))
        
        return geometry_list
    
    # Define a function to create an empty image with an overlap percentage band
    def create_empty_image_with_overlap(grid):
        # Define a function to calculate overlap percentage
        def calculate_overlap_percentage(feature):
            # Extract overlap percentage property
            overlap_percentage = ee.Number(feature.get('overlap_percentage'))
            # Return a feature with overlap percentage band
            return ee.Feature(feature.geometry()).set({'overlap_percentage_band': overlap_percentage})
        
        # Map the function over the grid feature collection
        overlap_with_band = grid.map(calculate_overlap_percentage)
        
        # Convert the feature collection to an image
        overlap_image = overlap_with_band.reduceToImage(properties=['overlap_percentage_band'], reducer=ee.Reducer.first())
        
        # Source image converted to Float64
        source_image = overlap_image.toDouble()
        
        # Convert the source raster image to Float64 and set all values to 1
        float_image = overlap_image.toDouble().multiply(0).add(1)
        
        # Get the projection of the raster image
        image_projection = overlap_image.projection()
        
        # Convert grid to Float64 and set overlap_percentage
        grid_float = overlap_percentage.map(lambda feature: feature.set('overlap_percentage', ee.Number(feature.get('overlap_percentage')).toDouble()))
        
        # Reproject grid to match the projection of the raster image
        grid_reprojected = grid_float.map(lambda feature: feature.transform(image_projection))
        
        # Paint the grid features onto an empty image with 'overlap_percentage' attribute
        painted_image = ee.Image().toDouble().paint(grid_reprojected, 'overlap_percentage')
        
        # Update the mask of the painted image using the original image
        updated_image = painted_image.updateMask(float_image.select(0))
        
        # Add the overlap percentage band to the original image and cast it to Float64
        new_image = ee.Image(source_image.addBands(updated_image.rename('overlap_percentage')))
        
        # Select only the 'overlap_percentage' band
        new_image = new_image.select(['overlap_percentage'])
        
        return new_image
    
    # OCEAN OVERLAP FUNCTION

    # Import global water body boundary spatial data
    water_polygons_collection = ee.FeatureCollection('projects/ee-global-indicators/assets/GUHVI/water_polygons')

    # Filter the water polygons to only include those that intersect with the city boundary
    intersecting_water_bodies = water_polygons_collection.filterBounds(geometry)

    # Merge (union) the intersecting water polygons into a single geometry
    merged_water_body_geometry = intersecting_water_bodies.union().geometry()

    # Convert the geometry to a single feature
    merged_water_body_feature = ee.Feature(merged_water_body_geometry)

    # Define a function to calculate intersection area and overlap percentage
    def calculate_ocean_overlap(feature):
        # Calculate the intersection between the city boundary and the grid square
        intersection = feature.intersection(merged_water_body_feature, maxError=1)
        
        # Check if the intersection is empty
        if intersection is not None:
            # Calculate the area of the grid square
            area = feature.geometry().area(maxError=1)
            
            # Calculate the area of intersection between the grid square and the water
            intersection_area = intersection.area(maxError=1)
            
            # Calculate the percentage area overlap
            overlap_percentage = intersection_area.divide(area).multiply(100)
            
            # Invert the overlap percentage
            inverted_overlap_percentage = ee.Number(100).subtract(overlap_percentage)
            
            # Return the feature with additional properties
            return feature.set({
                'overlap_percentage': inverted_overlap_percentage
            })
        else:
            # If there is no intersection, set overlap properties to 100
            return feature.set({
                'overlap_percentage': 100
            })
            
    # PREPARE GRID

    # Define geometry with margin error of 1 and buffer distance of 1km
    geometry = urban_study_region_fc.geometry(1)
    buffered_geometry = geometry.buffer(distance=1000)

    # Call functions to create grid and build geometry list
    grid = make_grid(buffered_geometry, guhvi_scale)
    geometries = build_geometry_list(grid, 10000)

    # Convert grid to a feature collection
    grid_collection = ee.FeatureCollection(grid)

    # Map the function over the grid feature collection
    overlap_percentage = grid.map(calculate_ocean_overlap)

    # Create an empty image with overlap percentage band
    empty_image_with_overlap = create_empty_image_with_overlap(overlap_percentage)

    # DEFINE DATA PREPARATION FUNCTIONS

    # Function to perform nearest neighbour filling on holes in raster data
    def fill_blank_pixels_2km(image, band):
        # Select the specified band from the image
        band_select = image.select(band)
        
        # Fill holes using nearest neighbor mean at a 3km radius
        filled_image = band_select.focal_mean(
            radius=2000,
            units='meters',
            kernelType='square'
        )
        
        # Clip the result to the city boundary
        clipped_image = filled_image.clip(urban_study_region_fc)

        # Use the original band where the filled image has values equal to or greater than 0
        overlay_image = clipped_image.where(clipped_image.gte(0), band_select)
        
        # Update the original image with the modified band
        updated_image = image.addBands(overlay_image.rename('filled'))
        
        # Convert data type to Float64
        float_image = updated_image.toDouble()
        
        return float_image

    # Function to perform nearest neighbour filling on holes in raster data
    def fill_blank_pixels_5km(image, band):
        # Select the specified band from the image
        band_select = image.select(band)
        
        # Fill holes using nearest neighbor mean at a 3km radius
        filled_image = band_select.focal_mean(
            radius=5000,
            units='meters',
            kernelType='square'
        )
        
        # Clip the result to the city boundary
        clipped_image = filled_image.clip(urban_study_region_fc)

        # Use the original band where the filled image has values equal to or greater than 0
        overlay_image = clipped_image.where(clipped_image.gte(0), band_select)
        
        # Update the original image with the modified band
        updated_image = image.addBands(overlay_image.rename('filled'))
        
        # Convert data type to Float64
        float_image = updated_image.toDouble()
        
        return float_image

    # Function to change negative/positive sign for NDVI calculation
    def flip_sign(image, band):
        # Select the specific band
        select_band = image.select(band)
        
        # Multiply the band by -1 to change the sign
        flipped_band = select_band.multiply(-1)
        
        # Add the modified band as a new band to the original image
        flipped_image = image.addBands(flipped_band.rename('flipped'))
        
        return flipped_image

    # Function to invert band for LSA calculation
    def invert_band(image, band_name, top_value):
        # Get the specified band
        band = image.select(band_name)
        
        # Invert the band by subtracting each pixel value from the top value
        inverted_band = ee.Image(top_value).subtract(band)
        
        # Add the inverted band to the original image
        inverted_image = image.addBands(inverted_band.rename('inverted'))
        
        return inverted_image

    # Function to remap and convert band based on a new order for LCZ calculation
    def remap_and_convert_band(image, band, new_order):
        # Get band
        original_band = image.select(band)
        
        # Remap the original band to the custom order
        remapped_band = original_band.remap(list(range(1, 18)), new_order)
        
        # Add the remapped and converted bands to the image
        remapped_image = image.addBands(remapped_band.rename('remapped')).toInt32()

        return remapped_image
    
    # DEFINE NORMALISATION FUNCTIONS

    # Function to normalise a given band for LST, LSA, PopD, PopV, SHDI, IMR calculation
    def normalise_band(image, band, original_min, original_max):
        # Select the band of interest
        normalised_image = image.select([band])
        
        overlap_percentage = image.select(['overlap_percentage'])

        # Define a custom normalization formula considering overlap_percentage
        normalised_band = normalised_image.expression(
            'clamp(((((value - min) / (max - min)) * 100) * (overlap_percentage / 100)), 0, 100)',
            {
                'value': normalised_image,
                'min': original_min,
                'max': original_max,
                'overlap_percentage': overlap_percentage,
            }
        ).rename('normalised_band')

        # Add the normalized band to the original image as a new band
        result_image = image.addBands(normalised_band)

        return result_image

    # Function to normalise a given band for NDVI and NDBI calculation
    def normalise_band_ndxi(image, band, original_min, original_max):
        # Select the band of interest
        normalised_image = image.select([band])
        
        overlap_percentage = image.select(['overlap_percentage'])

        # Define a custom normalization formula considering overlap_percentage
        normalised_band = normalised_image.expression(
            'clamp((((value - (min)) / (max - (min))) * 100) * (overlap_percentage / 100), 0, 100)',
            {
                'value': normalised_image,
                'min': original_min,
                'max': original_max,
                'overlap_percentage': overlap_percentage,
            }
        ).rename('normalised_band')

        # Add the normalized band to the original image as a new band
        result_image = image.addBands(normalised_band)

        return result_image

    # Function to normalise a given band for LCZ calculation
    def normalise_band_lcz(image, band, original_min, original_max):
        # Select the band of interest
        normalised_image = image.select([band])
        
        overlap_percentage = image.select(['overlap_percentage'])

        # Define a custom normalization formula considering overlap_percentage
        normalised_band = normalised_image.expression(
            'clamp((((value - min) / (max - min)) * overlap_percentage), 0, 100)',
            {
                'value': normalised_image,
                'min': original_min,
                'max': original_max,
                'overlap_percentage': overlap_percentage,
            }
        ).rename('normalised_band')

        # Add the normalized band to the original image as a new band
        result_image = image.addBands(normalised_band)

        return result_image

    # Function to normalise a given band for CDR calculation
    def normalise_band_nulls(image, band, original_min, original_max):
        # Select the band of interest
        normalised_image = image.select([band])
        
        overlap_percentage = image.select(['overlap_percentage'])

        # Define a custom normalization formula considering overlap_percentage
        normalised_band = normalised_image.expression(
            'clamp(((((value - min) / (max - min)) * 100) * (overlap_percentage / 100)), 0, 100)',
            {
                'value': normalised_image,
                'min': original_min,
                'max': original_max,
                'overlap_percentage': overlap_percentage,
            }
        ).rename('normalised_band')
        
        # Replace null values with 0
        normalised_band_masked = (normalised_band.unmask(0)).toDouble()

        # Add the normalized band to the original image as a new band
        result_image = image.addBands(normalised_band_masked)
        
        # Clip to city after filling nulls with 0
        result_image_clipped = result_image.clip(urban_study_region_fc)

        return result_image_clipped

    # CALCULATE HOTTEST THIRD OF THE YEAR (MODIS)
    # https://developers.google.com/earth-engine/datasets/catalog/MODIS_061_MOD11A1

    # Calculate the start and end years using previous target year input
    start_year = target_year - 5

    # Define the start and end dates as strings
    start_date = f"{start_year}-01-01"
    end_date = f"{target_year}-01-01"

    # Load MODIS data and add the Celsius band
    modis_collection = ee.ImageCollection("MODIS/061/MOD11A1") \
        .filterDate(start_date, end_date)

    # Function to add LST in Celsius as a new band
    def convert_to_celsius(image):
        # Convert LST from Kelvin to Celsius for daytime LST
        lst_day = image.select('LST_Day_1km').multiply(0.02).subtract(273.15).rename('LST')
        
        # Add the Celsius band to the image
        return image.addBands(lst_day)

    # Apply the function to the image collection
    modis_collection_with_celsius = modis_collection.map(convert_to_celsius)

    # Function to calculate monthly statistics (average of maximum LST for each month over 5 years)
    def calculate_monthly_stat(collection, reducer, month, stat_name):
        # Filter collection by month
        filtered = collection.filter(ee.Filter.calendarRange(month, month, 'month')).map(lambda img: img.clip(urban_study_region_fc))
        
        # Get the best pixel based on 'LST'
        stat_image = filtered.qualityMosaic('LST')
        
        # Reduce to get the statistical value (mean of maximum LST over 5 years)
        lst_stat = stat_image.select('LST').reduceRegion(
            reducer=reducer, geometry=geometry, scale=guhvi_scale, bestEffort=True
        ).get('LST')
        
        # Add metadata for month and stat value
        return stat_image.set('month', month).set(stat_name, lst_stat)

    # Calculate monthly average LST for each month across the 5-year period
    monthly_mean = ee.List.sequence(1, 12).map(lambda m: calculate_monthly_stat(modis_collection_with_celsius, ee.Reducer.mean(), m, 'mean_lst'))

    # Convert to ImageCollection
    monthly_mean_collection = ee.ImageCollection.fromImages(monthly_mean)

    # Function to calculate 4-month period average (°C) starting from the current month
    def calculate_4month_avg(monthly_stats, start_month):
        # Define the four months for the calculation
        months_to_consider = [(start_month + i - 1) % 12 + 1 for i in range(4)]
        
        # Retrieve the mean LST for each of the four months
        neighbor_values = [
            monthly_stats.filter(ee.Filter.eq('month', m)).first().get('mean_lst')
            for m in months_to_consider
        ]
        
        # Calculate the average of the four months
        return ee.Number(ee.List(neighbor_values).reduce(ee.Reducer.mean())), months_to_consider

    # Print average LST for each month and calculate 4-month period average (°C)
    print("Monthly Mean LST and Consecutive 4-Month Period Mean (°C):")
    monthly_stats = monthly_mean_collection.toList(12)

    max_4month_avg = -float('inf')
    max_month_with_neighbors = None

    for month in range(1, 13):
        month_data = ee.Image(monthly_stats.get(month - 1))
        month_mean_lst = month_data.get('mean_lst').getInfo()
        if month_mean_lst is not None:
            consecutive_4month_avg, months_to_consider = calculate_4month_avg(monthly_mean_collection, month)
            consecutive_4month_avg = consecutive_4month_avg.getInfo()
            month_names = ', '.join([f"Month {m}" for m in months_to_consider])
            print(f"Month {month}: Mean LST = {month_mean_lst:.3f} °C, "
                f"Consecutive 4-Month Period ({month_names}) Mean = {consecutive_4month_avg:.3f} °C")
            if consecutive_4month_avg > max_4month_avg:
                max_4month_avg = consecutive_4month_avg
                max_month_with_neighbors = month
        else:
            print(f"Month {month}: No Data")

    # Print the month with maximum Consecutive 4-Month Period Mean
    print(f"\nHottest Consecutive 4-Month Period begins with month number {max_month_with_neighbors}, with a mean temperature of {max_4month_avg:.3f} °C")

    # Define the hottest 4-month period based on Consecutive 4-Month Period Mean
    def get_date_range_4months(center_month, year):
        start_month = center_month
        end_month = (center_month + 4 - 1) % 12 + 1

        start_date = f"{year}-{start_month:02d}-01"
        # Calculate the end month
        if start_month > end_month:
            # Adjust year for end of the period
            end_date = f"{year + 1}-{end_month:02d}-01"
        else:
            end_date = f"{year}-{end_month:02d}-01"

        return start_date, end_date

    # Get window start and end dates for hottest 4-month period
    hottest_start_date, hottest_end_date = get_date_range_4months(max_month_with_neighbors, target_year)
    print(f"Hottest 4-Month Period: Start = {hottest_start_date}, End = {hottest_end_date}") 
    
    # LAND SURFACE TEMPERATURE (LST) - LANDSAT-8 SR

    # Function to mask clouds from Landsat 8 Collection 2, Level 2 using the QA_PIXEL band (CFMask).
    def mask_landsat8_sr_clouds(image):
        qa_mask = image.select('QA_PIXEL').bitwiseAnd(int('11111', 2)).eq(0)
        saturation_mask = image.select('QA_RADSAT').eq(0)

        optical_bands = image.select('SR_B.*').multiply(0.0000275).add(-0.2)
        thermal_bands = image.select('ST_B.*').multiply(0.00341802).add(149.0)

        return image.addBands(optical_bands, None, True) \
            .addBands(thermal_bands, None, True) \
            .updateMask(qa_mask) \
            .updateMask(saturation_mask)

    # Map the function over one year of data
    landsat_collection = ee.ImageCollection("LANDSAT/LC08/C02/T1_L2") \
        .filterDate(hottest_start_date, hottest_end_date) \
        .map(mask_landsat8_sr_clouds)

    # Calculate LST
    def calculate_lst(image):
        st = image.select('ST_B10')
        lst = st.subtract(273.15).rename('LST')
        return image.addBands(lst)

    # Create a collection attributed with LST data
    collection_with_lst = landsat_collection.map(calculate_lst)

    # Calculate the overall average LST for the 12 monthly maximums
    mean_lst = collection_with_lst.select('LST').mean()

    # Clip the LST image to the cityBoundary
    lst_clipped = mean_lst.clip(urban_study_region_fc)

    # Apply the 2km radius fill function
    lst_filled = fill_blank_pixels_2km((lst_clipped.toDouble()), 'LST')
    
    # LAND SURFACE ALBEDO (LSA) - LANDSAT-8 TOA

    # Define the mask Landsat function
    def mask_landsat8_toa_clouds(image):
        qa = image.select('QA_PIXEL')
        mask = qa.bitwiseAnd(1 << 3).eq(0)
        return image.updateMask(mask)

    # Define the albedo function
    def albedo(image):
        alb = image.expression(
            "((0.356*blue)+(0.130*red)+(0.373*nir)+(0.085*swir)+(0.072*swir2)- 0.018)/ 1.016",
            {
                'blue': image.select('B1'),
                'red': image.select('B3'),
                'nir': image.select('B4'),
                'swir': image.select('B5'),
                'swir2': image.select('B7')
            }
        )
        return image.addBands(alb.rename("albedo"))

    # Load Landsat 8 TOA collection, apply the albedo function, and filter by date and region
    landsat_toa_dataset = (ee.ImageCollection("LANDSAT/LC08/C02/T1_TOA")
                        .filterDate(hottest_start_date, hottest_end_date)
                        .filterBounds(geometry)
                        .map(mask_landsat8_toa_clouds)
                        .map(albedo))

    # Select only the albedo band and calculate the mean
    albedo_mean = landsat_toa_dataset.select("albedo").mean()

    # Clip to city
    lsa_clipped = albedo_mean.clip(urban_study_region_fc)

    # Apply the 2km radius fill function
    lsa_filled = fill_blank_pixels_2km((lsa_clipped.toDouble()), 'albedo')
    
    # NORMALISED DIFFERENCE VEGETATION INDEX (NDVI) - SENTINEL-2 SR

    # Function to mask clouds from Sentinel 2 imagery using the QA band
    def mask_sentinel2_clouds(image):
        qa = image.select('QA60')
        
        # Bits 10 and 11 are clouds and cirrus, respectively
        cloud_bit_mask = 1 << 10
        cirrus_bit_mask = 1 << 11
        
        # Both flags should be set to zero, indicating clear conditions
        mask = qa.bitwiseAnd(cloud_bit_mask).eq(0).And(qa.bitwiseAnd(cirrus_bit_mask).eq(0))
        
        # Return the masked and scaled data, without the QA bands
        return image.updateMask(mask).divide(10000).select(["B.*"]).copyProperties(image, ["system:time_start"])

    # Load Sentinel-2 SR data using dates for the hottest month of the year
    sentinel_collection_hottest_period = ee.ImageCollection("COPERNICUS/S2_SR_HARMONIZED") \
        .filterBounds(bounding_box) \
        .filterDate(hottest_start_date, hottest_end_date) \
        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 90)) \
        .map(mask_sentinel2_clouds)

    # Calculate NDVI
    def calculate_ndvi(image):
        nir = image.select('B8')
        red = image.select('B4')
        ndvi = nir.subtract(red).divide(nir.add(red)).rename('NDVI')
        return image.addBands(ndvi)

    # Apply NDVI calculation to the image collection
    sentinel_hottest_period_collection_ndvi = sentinel_collection_hottest_period.map(calculate_ndvi)

    # Calculate mean NDVI
    hottest_period_ndvi = sentinel_hottest_period_collection_ndvi.select('NDVI').mean()

    # Clip the NDVI image to the city boundary
    ndvi_clipped = hottest_period_ndvi.clip(urban_study_region_fc)
    
    # NORMALISED DIFFERENCE BUILT-UP INDEX (NDBI) - SENTINEL-2 SR

    # Calculate (NDBI).
    def calculate_ndbi(image):
        swir = image.select('B11')
        nir = image.select('B8')
        ndbi = swir.subtract(nir).divide(swir.add(nir)).rename('NDBI')
        return image.addBands(ndbi)

    # Apply NDBI calculation to the image collection
    sentinel_hottest_period_collection_ndbi = sentinel_collection_hottest_period.map(calculate_ndbi)

    # Calculate mean NDBI
    hottest_period_ndbi = sentinel_hottest_period_collection_ndbi.select('NDBI').mean()

    # Clip the NDBI image to the city boundary
    ndbi_clipped = hottest_period_ndbi.clip(urban_study_region_fc)
    
    # LOCAL CLIMATE ZONES (LCZ)
    # https://developers.google.com/earth-engine/datasets/catalog/RUB_RUBCLIM_LCZ_global_lcz_map_latest

    # Create an ImageCollection and mosaic it
    dataset = ee.ImageCollection("RUB/RUBCLIM/LCZ/global_lcz_map/latest").mosaic()

    # Clip to the specified region
    lcz_clipped = dataset.clip(urban_study_region_fc)

    # Only select relevant band
    lcz_cleaned = lcz_clipped.select('LCZ_Filter')
    
    # POPULATION DENSITY (POPD) - GHS Population Grid, Epoch 2025, 1km Resolution, Mollweide EPSG:54009
    # https://human-settlement.emergency.copernicus.eu/download.php?ds=pop 
    
    # Define a dictionary to store FeatureCollections for various data
    ghs_pop = ee.Image('projects/ee-global-indicators/assets/GUHVI/POPD')

    # Clip the SHDI FeatureCollection to the specified city
    ghs_pop_clipped = ghs_pop.clip(urban_study_region_fc)

    # Rename the band to 'pop'
    ghs_pop_clipped = ghs_pop_clipped.rename('ghs_pop')
    
    # VULNERABLE POPULATION (POPV) - generated from WorldPop
    # https://developers.google.com/earth-engine/datasets/catalog/WorldPop_GP_100m_pop_age_sex_cons_unadj

    # Load WorldPop data
    world_pop_dataset_popv = ee.ImageCollection("WorldPop/GP/100m/pop_age_sex_cons_unadj")

    # Custom function to calculate percentage of vulnerable population and append it as a new attribute
    def add_percent_popv(image):
        # Select relevant age groups of 4- and 65+ for both men and women
        vulnerable_age_group = ['M_0', 'M_1', 'M_65', 'M_70', 'M_75', 'M_80', 'F_0', 'F_1', 'F_65', 'F_70', 'F_75', 'F_80']
        
        # Calculate the sum of vulnerable population for each pixel
        vulnerable_pop_sum = image.select(vulnerable_age_group).reduce(ee.Reducer.sum())
        
        # Calculate the total population
        total_population = image.select('population')
        
        # Calculate the percentage of vulnerable population for each pixel
        percent_vulnerable_pop = vulnerable_pop_sum.divide(total_population).multiply(100).rename('percent_popv')
        
        # Add the new band to the image
        image_with_vulnerable_pop = image.addBands(percent_vulnerable_pop)
        
        return image_with_vulnerable_pop

    # Map the custom function over the dataset
    image_with_popv = (world_pop_dataset_popv.map(add_percent_popv)).mosaic()

    # Select relevant bands
    image_with_popv_relevant_bands = image_with_popv.select('percent_popv')

    # Clip the mean image to the city boundary
    popv_clipped = image_with_popv_relevant_bands.clip(urban_study_region_fc)

    # Create a mask for non-zero values
    popv_non_zero_mask = popv_clipped.neq(0)

    # Apply the mask to popv_clipped
    popv_clipped_non_zero = popv_clipped.updateMask(popv_non_zero_mask)
    
    # CHILD DEPENDENCY RATIO (CDR) - generated from WorldPop
    # https://developers.google.com/earth-engine/datasets/catalog/WorldPop_GP_100m_pop_age_sex_cons_unadj

    # Load WorldPop data
    world_pop_dataset_cdr = ee.ImageCollection("WorldPop/GP/100m/pop_age_sex_cons_unadj")

    # Custom function to calculate percentage of vulnerable population and append it as a new attribute
    def add_child_dependecy_ratio(image):
        # Select relevant age groups for both men and women
        child_age_group = ['M_0', 'M_1', 'M_5', 'M_10', 'F_0', 'F_1', 'F_5', 'F_10']
        
        working_age_group = ['M_15', 'M_20', 'M_25', 'M_30', 'M_35', 'M_40', 'M_45', 'M_50', 'M_55', 'M_60',
                            'F_15', 'F_20', 'F_25', 'F_30', 'F_35', 'F_40', 'F_45', 'F_50', 'F_55', 'F_60']
        
        # Calculate the sum of young age group for each pixel
        child_age_sum = image.select(child_age_group).reduce(ee.Reducer.sum())
        
        # Calculate the sum of working age group for each pixel
        working_age_sum = image.select(working_age_group).reduce(ee.Reducer.sum())

        # Calculate the total population
        total_population = image.select('population')

        # Calculate percentage of total
        child_age_percent = child_age_sum.divide(total_population)

        # Calculate percentage of total
        working_age_percent = working_age_sum.divide(total_population)
        
        # Calculate the child dependency ratio for each pixel
        child_dependency_ratio = child_age_percent.divide(working_age_percent).multiply(100).rename('child_dependency_ratio')
        
        # Add the new rounded band to the image
        cdr_image = image.addBands(child_dependency_ratio.rename('child_dependency_ratio'))
        
        return cdr_image

    # Map the custom function over the dataset
    image_with_cdr = (world_pop_dataset_cdr.map(add_child_dependecy_ratio)).mosaic()

    # Select relevant bands
    image_with_cdr_relevant_bands = image_with_cdr.select('child_dependency_ratio')

    # Clip the mean image to the city boundary
    cdr_clipped = image_with_cdr_relevant_bands.clip(urban_study_region_fc)

    # Create a mask for non-zero values
    cdr_non_zero_mask = cdr_clipped.neq(0)

    # Apply the mask to cdr_clipped
    cdr_clipped_non_zero = cdr_clipped.updateMask(cdr_non_zero_mask)
    
    # DEFINE SHDI & IMR DATA INPUTS

    # Define the two images
    shdi = ee.Image('projects/ee-global-indicators/assets/GUHVI/SHDI')
    imr = ee.Image('projects/ee-global-indicators/assets/GUHVI/IMR')

    # SUBNATIONAL HUMAN DEVELOPMENT INDEX (SHDI)

    # Clip the SHDI FeatureCollection to the specified city
    shdi_clipped = shdi.clip(urban_study_region_fc)
    # Apply the 5km radius fill function
    shdi_filled = fill_blank_pixels_5km((shdi_clipped.toDouble()), 'b1')

    # INFANT MORTALITY RATES (IMR)

    # Clip the IMR FeatureCollection to the specified city
    imr_clipped = imr.clip(urban_study_region_fc)
    # Apply the 5km radius fill function
    imr_filled = fill_blank_pixels_5km((imr_clipped.toDouble()), 'b1')
    
    # HEAT EXPOSURE INDEX (HEI) - SUB-INDEX 1

    # Land Surface Temperature (LST) -------------------------------------------------------------------------------------------------

    # Calculate the minimum and maximum values
    min_max_lst = lst_filled.reduceRegion(
        reducer=ee.Reducer.minMax(),
        geometry=geometry,
        scale=guhvi_scale
    )

    # Extract the min and max values
    min_lst = min_max_lst.getNumber('filled_min')
    max_lst = min_max_lst.getNumber('filled_max')

    #print("Minimum LST:", min_lst.getInfo())
    #print("Maximum LST:", max_lst.getInfo())

    # Copy band 'overlap_percentage'
    lst_overlap_image = lst_filled.addBands(empty_image_with_overlap.select(['overlap_percentage'])).toDouble()
    # Define the known range and input band for each input before normalisation and inversion
    lst_input_original_min = min_lst
    lst_input_original_max = max_lst
    lst_input_band = 'filled'
    # Normalise
    lst_normalised_image = normalise_band(lst_overlap_image, lst_input_band, lst_input_original_min, lst_input_original_max)

    # Perform Equal Weighting & Create HEI -------------------------------------------------------------------------------------------

    # Calculate the equal-weighted average of normalized values for each pixel
    # Since, HEI only has one input, the values will remain unchanged, however
    # still perform this step since it will remove the now unnecessary 'LST' and 'overlap_percentage' bands
    hei_equal_weighted_average_image = ee.Image.cat([
        lst_normalised_image.select('normalised_band'),
    ]).reduce(ee.Reducer.mean()).rename('equal_weighted_average')

    # Calculate the overall mean for the equal-weighted average index
    hei_overall_mean = hei_equal_weighted_average_image.reduceRegion(
        reducer=ee.Reducer.mean(),
        geometry=geometry,
        scale=guhvi_scale
    ).getNumber('equal_weighted_average')

    # Clip the classified image to the specified geometry
    hei_equal_weighted_average_image_clipped = hei_equal_weighted_average_image.clip(urban_study_region_fc)
    
    # HEAT SENSITIVITY INDEX (HSI) - SUB-INDEX 2

    # Land Surface Albedo (LSA) ------------------------------------------------------------------------------------------------------

    # Invert band
    lsa_inverted = invert_band(lsa_filled, 'filled', 1)

    # Calculate the minimum and maximum values
    min_max_lsa = lsa_inverted.reduceRegion(
        reducer=ee.Reducer.minMax(),
        geometry=geometry,
        scale=guhvi_scale
    )

    min_lsa = min_max_lsa.getNumber('inverted_min')
    max_lsa = min_max_lsa.getNumber('inverted_max')

    #print("Minimum LSA:", min_lsa.getInfo())
    #print("Maximum LSA:", max_lsa.getInfo())

    # Copy band 'overlap_percentage'
    lsa_overlap_image = lsa_inverted.addBands(empty_image_with_overlap.select(['overlap_percentage'])).toDouble()
    # Define the known range and input band for each input before normalisation
    lsa_input_original_min = min_lsa
    lsa_input_original_max = max_lsa
    lsa_input_band = 'inverted'
    # Normalise
    lsa_normalised_image = normalise_band(lsa_overlap_image, lsa_input_band, lsa_input_original_min, lsa_input_original_max)

    # Normalised Difference Vegetation Index (NDVI) ----------------------------------------------------------------------------------

    # Flip negative and positive signs to effectively invert since high NDVI infers lower heat vulnerability
    ndvi_flipped = flip_sign(ndvi_clipped, 'NDVI')

    # Calculate the minimum and maximum values
    min_max_ndvi = ndvi_flipped.reduceRegion(
        reducer=ee.Reducer.minMax(),
        geometry=geometry,
        scale=guhvi_scale
    )

    min_ndvi = min_max_ndvi.getNumber('flipped_min')
    max_ndvi = min_max_ndvi.getNumber('flipped_max')

    #print("Minimum NDVI:", min_ndvi.getInfo())
    #print("Maximum NDVI:", max_ndvi.getInfo())

    # Copy band 'overlap_percentage'
    ndvi_overlap_image = ndvi_flipped.addBands(empty_image_with_overlap.select(['overlap_percentage'])).toDouble()
    # Define the known range and input band for each input before normalisation
    ndvi_input_original_min = min_ndvi
    ndvi_input_original_max = max_ndvi
    ndvi_input_band = 'flipped'
    # Normalise
    ndvi_normalised_image = normalise_band_ndxi(ndvi_overlap_image, ndvi_input_band, ndvi_input_original_min, ndvi_input_original_max)

    # Normalised Difference Built-Up Index (NDBI) ------------------------------------------------------------------------------------

    # Calculate the minimum and maximum values
    min_max_ndbi = ndbi_clipped.reduceRegion(
        reducer=ee.Reducer.minMax(),
        geometry=geometry,
        scale=guhvi_scale
    )

    min_ndbi = min_max_ndbi.getNumber('NDBI_min')
    max_ndbi = min_max_ndbi.getNumber('NDBI_max')

    #print("Minimum NDBI:", min_ndbi.getInfo())
    #print("Maximum NDBI:", max_ndbi.getInfo())

    # Copy band 'overlap_percentage'
    ndbi_overlap_image = ndbi_clipped.addBands(empty_image_with_overlap.select(['overlap_percentage'])).toDouble()
    # Define the known range and input band for each input before normalisation
    ndbi_input_original_min = min_ndbi
    ndbi_input_original_max = max_ndbi
    ndbi_input_band = 'NDBI'
    # Normalise
    ndbi_normalised_image = normalise_band_ndxi(ndbi_overlap_image, ndbi_input_band, ndbi_input_original_min, ndbi_input_original_max)

    # Local Climate Zones (LCZ) ------------------------------------------------------------------------------------------------------

    # List from 1-17 to include all climate zones
    original_order = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]

    # Modify custom_order from least heat retaining to most heat retaining based on order shown here
    # https://developers.google.com/earth-engine/datasets/catalog/RUB_RUBCLIM_LCZ_global_lcz_map_latest#bands
    custom_order = [17, 11, 12, 13, 14, 9, 6, 16, 7, 4, 5, 10, 8, 1, 3, 2, 15]

    def generate_new_order(original_order, custom_order):
        # Initialize an empty list to store the new order
        new_order = []
        
        # Iterate over each element in the original order
        for element in original_order:
            # Find the index of the element in custom_order
            index_in_custom_order = custom_order.index(element)
            
            # Append the index position to new_order (incremented by 1 as per your specification)
            new_order.append(index_in_custom_order + 1)
        
        return new_order

    # Generate new_order using the function
    lcz_new_order = generate_new_order(original_order, custom_order)
    # Remap and convert band
    lcz_remapped_converted = remap_and_convert_band(lcz_cleaned, 'LCZ_Filter', lcz_new_order)

    # Calculate the minimum and maximum values
    min_max_lcz = lcz_remapped_converted.reduceRegion(
        reducer=ee.Reducer.minMax(),
        geometry=geometry,
        scale=guhvi_scale
    )

    min_lcz = min_max_lcz.getNumber('remapped_min')
    max_lcz = min_max_lcz.getNumber('remapped_max')

    #print("Minimum LCZ:", min_lcz.getInfo())
    #print("Maximum LCZ:", max_lcz.getInfo())

    # Copy band 'overlap_percentage'
    lcz_overlap_image = lcz_remapped_converted.addBands(empty_image_with_overlap.select(['overlap_percentage'])).toDouble()
    # Define the known range and input band for each input before normalisation
    lcz_input_original_min = min_lcz
    lcz_input_original_max = max_lcz
    lcz_input_band = 'remapped'
    # Normalise
    lcz_normalised_image = normalise_band_lcz(lcz_overlap_image, lcz_input_band, lcz_input_original_min, lcz_input_original_max)

    # Pop Density (POPD) -------------------------------------------------------------------------------------------------------------

    # Calculate the minimum and maximum values
    min_max_popd = ghs_pop_clipped.reduceRegion(
        reducer=ee.Reducer.minMax(),
        geometry=geometry,
        scale=guhvi_scale
    )

    min_popd = min_max_popd.getNumber('ghs_pop_min')
    max_popd = min_max_popd.getNumber('ghs_pop_max')

    #print("Minimum POPD:", min_popd.getInfo())
    #print("Maximum POPD:", max_popd.getInfo())

    # Copy band 'overlap_percentage'
    popd_overlap_image = ghs_pop_clipped.addBands(empty_image_with_overlap.select(['overlap_percentage'])).toDouble()
    # Define the known range and input band for each input before normalisation
    popd_input_original_min = min_popd
    popd_input_original_max = max_popd
    popd_band = 'ghs_pop'
    # Normalise
    popd_normalised_image = normalise_band(popd_overlap_image, popd_band, popd_input_original_min, popd_input_original_max)

    # Vulnerable Pop (POPV) ----------------------------------------------------------------------------------------------------------

    # Calculate the minimum and maximum values
    min_max_popv = popv_clipped_non_zero.reduceRegion(
        reducer=ee.Reducer.minMax(),
        geometry=geometry,
        scale=guhvi_scale
    )

    min_popv = min_max_popv.getNumber('percent_popv_min')
    max_popv = min_max_popv.getNumber('percent_popv_max')

    #print("Minimum POPV:", min_popv.getInfo())
    #print("Maximum POPV:", max_popv.getInfo())

    # Copy band 'overlap_percentage'
    popv_overlap_image = popv_clipped_non_zero.addBands(empty_image_with_overlap.select(['overlap_percentage'])).toDouble()
    # Define the known range and input band for each input before normalisation
    popv_input_original_min = min_popv
    popv_input_original_max = max_popv
    popv_band = 'percent_popv'
    # Normalise
    popv_normalised_image = normalise_band_nulls(popv_overlap_image, popv_band, popv_input_original_min, popv_input_original_max)

    # Perform Equal Weighting & Create HSI -------------------------------------------------------------------------------------------

    # Calculate the equal-weighted average of normalized values for each pixel
    hsi_equal_weighted_average_image = ee.Image.cat([
        lsa_normalised_image.select('normalised_band'),
        ndvi_normalised_image.select('normalised_band'),
        ndbi_normalised_image.select('normalised_band'),
        lcz_normalised_image.select('normalised_band'),
        popd_normalised_image.select('normalised_band'),
        popv_normalised_image.select('normalised_band'),
    ]).reduce(ee.Reducer.mean()).rename('equal_weighted_average')

    # Clip the classified image to the specified geometry
    hsi_equal_weighted_average_image_clipped = hsi_equal_weighted_average_image.clip(urban_study_region_fc)
    
    # ADAPTIVE CAPABILITY INDEX (ACI) - SUB-INDEX 3

    # Child Dependency Ratio (CDR) ---------------------------------------------------------------------------------------------------

    # Copy band 'overlap_percentage'
    cdr_overlap_image = cdr_clipped_non_zero.addBands(empty_image_with_overlap.select(['overlap_percentage'])).toDouble()
    # Define the known range and input band for each input before normalisation
    cdr_input_original_min = 0
    cdr_input_original_max = 100
    cdr_input_band = 'child_dependency_ratio'
    # Normalise
    cdr_normalised_image = normalise_band_nulls(cdr_overlap_image, cdr_input_band, cdr_input_original_min, cdr_input_original_max)

    # Subnational Human Development Index (SHDI) -------------------------------------------------------------------------------------

    # Copy band 'overlap_percentage'
    shdi_overlap_image = shdi_filled.addBands(empty_image_with_overlap.select(['overlap_percentage'])).toDouble()
    # Define the known range and input band for each input before normalisation
    shdi_input_original_min = 0
    shdi_input_original_max = 100
    shdi_input_band = 'filled'
    # Normalise
    shdi_normalised_image = normalise_band(shdi_overlap_image, shdi_input_band, shdi_input_original_min, shdi_input_original_max)

    # Infant Mortality Rates (IMR) ---------------------------------------------------------------------------------------------------

    # Copy band 'overlap_percentage'
    imr_overlap_image = imr_filled.addBands(empty_image_with_overlap.select(['overlap_percentage'])).toDouble()
    # Define the known range and input band for each input before normalisation
    imr_input_original_min = 0
    imr_input_original_max = 100
    imr_input_band = 'filled'
    # Normalise
    imr_normalised_image = normalise_band(imr_overlap_image, imr_input_band, imr_input_original_min, imr_input_original_max)

    # Perform Equal Weighting & Create ACI -------------------------------------------------------------------------------------------

    # Calculate the equal-weighted average of normalized values for each pixel
    aci_equal_weighted_average_image = ee.Image.cat([
        cdr_normalised_image.select('normalised_band'),
        shdi_normalised_image.select('normalised_band'),
        imr_normalised_image.select('normalised_band'),
    ]).reduce(ee.Reducer.mean()).rename('equal_weighted_average')

    # Clip the classified image to the specified geometry
    aci_equal_weighted_average_image_clipped = aci_equal_weighted_average_image.clip(urban_study_region_fc)
    
    # CREATE EQUAL WEIGHTED GUHVI IMAGE

    # Calculate the equal-weighted average of normalized values for each pixel
    guhvi_image = ee.Image.cat([
        hei_equal_weighted_average_image_clipped,
        hsi_equal_weighted_average_image_clipped,
        aci_equal_weighted_average_image_clipped,
    ]).reduce(ee.Reducer.mean()).rename('equal_weighted_average')

    # Calculate the overall median for the equal-weighted average index
    guhvi_overall_mean = guhvi_image.reduceRegion(
        reducer=ee.Reducer.mean(),
        geometry=geometry,
        scale=guhvi_scale
    ).getNumber('equal_weighted_average')

    # Clip the classified image to the specified geometry (city)
    guhvi_image_clipped = guhvi_image.clip(urban_study_region_fc)
    
    # CREATE GUHVI WITH QUINTILES

    # Calculate quintiles
    quintile_values = guhvi_image_clipped.reduceRegion(
        reducer=ee.Reducer.percentile([20, 40, 60, 80]),
        geometry=geometry,
        scale=guhvi_scale
    )

    # Print quintile values
    #print("Quintile values:", quintile_values.getInfo())

    # Define class thresholds
    class_thresholds = [
        float('-inf'),
        quintile_values.get('equal_weighted_average_p20'),
        quintile_values.get('equal_weighted_average_p40'),
        quintile_values.get('equal_weighted_average_p60'),
        quintile_values.get('equal_weighted_average_p80'),
        float('inf')
    ]

    # Convert computed objects to numeric values
    p80 = ee.Number(quintile_values.get('equal_weighted_average_p80'))
    p60 = ee.Number(quintile_values.get('equal_weighted_average_p60'))
    p40 = ee.Number(quintile_values.get('equal_weighted_average_p40'))
    p20 = ee.Number(quintile_values.get('equal_weighted_average_p20'))

    # Create a classified image based on 5 classes
    classified_image = guhvi_image_clipped.expression(
        "(b(0) > %f) ? 5 : (b(0) > %f) ? 4 : (b(0) > %f) ? 3 : (b(0) > %f) ? 2 : 1" % (
            p80.getInfo(),
            p60.getInfo(),
            p40.getInfo(),
            p20.getInfo()
        )
    )

    # Add GUHVI index band
    guhvi = guhvi_image_clipped.addBands(classified_image.rename('GUHVI_class')).toDouble()

    # Clip the classified image to the specified geometry (city)
    guhvi_clipped = guhvi.clip(urban_study_region_fc)
    
    def raster_to_vector_by_grid(raster, grid, scale):
        band_names = raster.bandNames()

        # Use reduceRegions to extract all bands
        vectors = raster.reduceRegions(
            collection=grid,
            reducer=ee.Reducer.mean().forEach(band_names),
            scale=scale,
        )

        # Filter out features that don't have valid data in any band
        valid_vectors = vectors.filter(ee.Filter.notNull(band_names))

        return valid_vectors
    
    raster_list = [
        ('lst', lst_normalised_image),
        ('hei', hei_equal_weighted_average_image_clipped),
        ('lsa', lsa_normalised_image),
        ('ndvi', ndvi_normalised_image),
        ('ndbi', ndbi_normalised_image),
        ('lcz', lcz_normalised_image),
        ('popd', popd_normalised_image),
        ('popv', popv_normalised_image),
        ('hsi', hsi_equal_weighted_average_image_clipped),
        ('cdr', cdr_normalised_image),
        ('shdi', shdi_normalised_image),
        ('imr', imr_normalised_image),
        ('aci', aci_equal_weighted_average_image_clipped),
        ('guhvi', guhvi_clipped),
    ]
    
    vector_results = {}

    for name, raster in raster_list:
        vector = raster_to_vector_by_grid(raster, grid_collection, guhvi_scale)
        vector_results[name] = vector

    def upload_guhvi_data(r, name, gdf):
        # Prepare column types from gdf columns
        band_columns = [col for col in gdf.columns if col != 'geometry']
        
        # SQL to drop and create the table
        create_table_sql = f"""
        DROP TABLE IF EXISTS guhvi_{name};
        
        CREATE TABLE guhvi_{name} (
            id SERIAL PRIMARY KEY,
            {"".join([f"{col} FLOAT," for col in band_columns])}
            geom GEOMETRY(Geometry, 4326)
        );
        """

        # SQL to insert a row
        insert_sql = f"""
        INSERT INTO guhvi_{name} ({", ".join(band_columns)}, geom)
        VALUES ({", ".join([f":{col}" for col in band_columns])}, ST_SetSRID(ST_GeomFromText(:geom), 4326));
        """

        # Execute in a transaction
        with r.engine.begin() as conn:
            conn.execute(text(create_table_sql))
            for _, row in gdf.iterrows():
                conn.execute(
                    text(insert_sql),
                    {**{col: row[col] for col in band_columns}, 'geom': row['geometry'].wkt}
                )

    for name, ee_fc in vector_results.items():
        gdf = geemap.ee_to_gdf(ee_fc)
        gdf.columns = [col.replace(':', '_').replace(' ', '_') for col in gdf.columns]
        gdf = gdf.drop(columns=[col for col in ['count', 'label'] if col in gdf.columns])
        upload_guhvi_data(r, name, gdf)


def global_urban_heat_vulnerability_index(codename):
    # simple timer for log file
    start = time.time()
    script = '_08_global_urban_heat_vulnerability_index'
    task = 'Compute Global Urban Heat Vulnerability Index (GUHVI)'
    r = ghsci.Region(codename)
    # Generate and upload GUHVI data
    compute_guhvi(codename, r)
    # output to completion log
    script_running_log(r.config, script, task, start)
    r.engine.dispose()


def main():
    try:
        codename = sys.argv[1]
    except IndexError:
        codename = None
    global_urban_heat_vulnerability_index(codename)


if __name__ == '__main__':
    main()